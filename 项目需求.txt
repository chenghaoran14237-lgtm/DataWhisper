. 项目目标（一句话版本）

做一个 Web 端 Excel AI 助手 Demo：



用户在网页上传 Excel + 输入自然语言需求 →



后端（FastAPI）读取和处理 Excel →



多次调用 OpenAI API 做分析/生成结果 →



把结果用“人类友好”的方式返回用户（文本 / 新表下载等）。

前端只负责交互壳子，后端 + LLM 调度 + Excel 处理是重点。

1. 总体架构共识

前端（Web 壳）

简单聊天式界面 + 文件上传控件

展示历史对话 & 显示 AI 分析结果

不直接持有任何 API Key，只跟你的后端说话

后端（FastAPI）——本项目主战场

对话管理（历史、summary、token 控制）

Excel 文件读写 & 预处理

业务流程编排（多步调用 LLM + 工具）

与 OpenAI API 通信（选择模型、处理错误、控制成本）

LLM 服务（OpenAI API）

模型本身是黑盒：你控制 prompt / messages / 次数 / 模型选型

不负责存储对话，也不负责任务状态

2. 功能需求

2.1 前端功能（壳就行，但要有）

页面结构

顶部：项目标题 + 简单说明（“Excel AI 助手 Demo”）

中间：聊天区域（展示用户问 + AI 回答）

侧边或顶部：文件上传区（只允许 Excel：.xlsx）

底部：输入框 + “发送”按钮

交互

上传或更换 Excel 文件（提示当前已选文件名）

输入指令，例如：

“帮我概括这个销售表的大致情况”

“找出销售最好的三个月并分析原因”

支持“继续追问”和“修改上一轮结果”的对话体验

结果展示

文本分析结果（Markdown 或简单格式）

预留一个入口：将来可以加“生成新 Excel 下载”的按钮（第一版可以先不做）

2.2 后端基础功能

2.2.1 Excel 文件处理

支持上传 .xlsx 文件

限制：

文件大小上限（比如 5MB / 10MB，避免一口气吞一个 ERP）

sheet 处理策略：默认处理第一个 sheet，后续可以支持指定 sheet

利用 pandas 做基本处理：

读取为 DataFrame

获取列名、行数、简单统计（计数、均值、缺失率）

生成一个“预览片段”（比如前 10 行，用于发给 LLM）

这一块是纯后端业务逻辑，不要交给 LLM 做。

2.2.2 对话记录 & “记忆系统”

你的需求要解决两个问题：



用户能多轮对话（“刚那段帮我改一下”、“再详细一点”）

不让上下文无限膨胀（token & 费用炸裂）

可以按照我们上次聊的思路，整理成明确需求：



消息存储表（messages）

字段概念：

session_id：一场对话的标识

role：user / assistant / system

content：文本内容

created_at

summarized: 是否已被纳入某次 summary

（可选）token_count: 该条消息的 token 预估值

总结表（summaries）

session_id

content：对该会话“到目前为止”的摘要

up_to_message_id：总结覆盖到哪条 message

created_at

构造每次请求上下文的规则

取该会话最新一条 summary（如果有），作为一条 system/assistant 消息

再取 up_to_message_id 之后的最近 N 条原始消息（未 summarized）

最后 append 当前这条 user 输入

控制整体 token 不超过某个上限（比如 2k 或 4k）

总结（summary）触发条件

不按“条数”，按“累计 token / 信息量”更合理

例如：自上次 summary 之后累积消息 token>1000 时，调用一次 LLM 做增量总结

2.2.3 token & 成本控制

需求点：

为每次请求传给 LLM 的 messages 设置一个 token 预算（比如 2k–4k）

每次在后端构造 messages 时，要估算长度，超过就裁剪历史

使用便宜模型作为默认（比如 gpt-4.1-mini / 最新的 mini 系列）

将模型名和最大 token、温度等配置放在环境变量或配置文件里，而不是硬编码

2.2.4 模型选择

优先使用：

免费配额 / 便宜价位的模型

支持中文、对表格数据理解还行的 chat 模型

逻辑上预留扩展：

以后可以切到别的模型（DeepSeek、本地模型）而不用改业务逻辑



-需求里可以写一句：

“模型参数（名称、温度、max_tokens）通过配置控制，后端调用逻辑不写死具体模型。”

2.2.5 输入安全 & 健壮性（你觉得“无所谓”的那块）

即便是 Demo，也有几件事值得写进需求：



对上传文件做：

类型校验（不接受 .exe、.zip）

大小限制（防止恶搞）

对文本输入做：

长度限制（比如 2k 字以内）

错误处理：

Excel 解析失败要返回清晰错误（而不是 500 白板）

LLM 调用失败要有“友好提示 + 后端日志”

不是为了防黑客，而是为了防“一不小心玩死自己”。

3. 业务层面的需求（agent 的“聪明”部分）

这是你最感兴趣的地方：怎么拆分需求、多次调用 API，让结果更专业。

以“Excel 分析助手”为例，可以写成这样的业务流程需求：



3.1 典型任务流程（以“分析销售数据表”为例）

文件上传阶段

用户上传 Excel，后端解析

后端生成一个“数据预览结构”，包括：

表头（列名和类型粗判）

前 N 行示例

行数 / 列数 / 缺失情况等基本统计

意图识别阶段（可选的小模型调用）

用户输入需求，如：



帮我看看哪些地区的销售表现最好，再提一些建议

调用一次 LLM，问：

这是哪类任务？（概括 / 对比 / 排名 / 异常检测 / 生成公式 / 生成代码）

粒度是什么？（按月份 / 按地区 / 按产品）

返回一个结构化结果，供后端使用

数据处理阶段（纯 Python）

根据意图（如果有）决定怎么用 pandas 操作 DataFrame：

分组统计

排序 / 筛选

找 top N

生成关键数值指标

结果解释生成阶段（主 LLM 调用）

把“数据处理结果 + 少量数据样本”拼成 prompt：

不直接把整个表丢进去

强调：这些是统计结果，请据此给出洞察和建议

LLM 生成结构化文本：

简要总结

若干条建议

建议可视化方式（不真的画图，只说“适合用柱状图对比 3 个地区”）

后续追问 / 修改阶段

用户可能继续说：



那只看 2024 年的数据再来一版



把建议写成发给领导的汇报语气

后端在会话中保留“当前任务状态”和必要的 DataFrame / 中间统计结果，不必每次重读 Excel

多轮对话时，既要带历史对话，也要带“任务上下文摘要”（比如当前过滤条件）

3.2 输出形式（结果如何给用户）

你刚才提出两种方式，都可以写进需求，并做一个“优先级”设定：



必做：文本预览

在前端展示 AI 生成的分析报告（支持换行 / 粗体等基本格式）

用户可以复制粘贴

可选扩展：生成新 Excel 下载

将“分析用到的部分结果”写成新的 DataFrame

例如：Top N 排名表、按条件过滤后的子表

提供一个“下载处理结果 Excel”按钮

第一版可以先不做，写在“未来迭代”里

4. 非功能需求 & 工程层面的补充

这些是容易被忽略，但很适合写进需求的点：



配置化

模型名 / API Key / token 限额 / 超时时间等，需要在 .env 或配置文件中控制

日志 & 调试

后端记录：

请求时间、耗时、成功/失败

LLM 调用失败的原因（HTTP 状态码、错误信息）

对话内容可以只部分记录或脱敏（至少要能调试）

可扩展性

以后可以增加：

新的“工具卡片”——如“文本润色”、“简历助手”、“代码解释器”

新的 LLM provider（DeepSeek、本地模型等等）

后端架构上预留一个“多 agent / 多工具”的扩展点（比如通过 agent_type 参数路由）

简单的限流/防炸

防止某个用户 / bug 造成疯狂请求：

单 IP / 单 session 每分钟请求上限（比如 20 次）